# Instalily Case Study

## Demo Video
https://www.loom.com/share/13120964c7534b63974e4571b0f493eb?sid=edf7104f-a3c7-49f9-9517-dbe08958a583

## ðŸ“Œ Project Overview
This project is an **appliance parts customer support assistant** case study, simulating an intelligent customer service system that can instantly answer questions related to appliance parts. The data source is the **PartSelect dataset** (`partselect_parts.json`).  
The system can handle the following types of queries:
- Part lookup and function descriptions
- Step-by-step installation guidance
- Model compatibility checks
- Repair and troubleshooting advice
- General maintenance and usage tips

The backend is built with **FastAPI** and implements a custom **RAG (Retrieval-Augmented Generation) retrieval pipeline**, supporting multiple LLM providers (default: OpenAI, switchable to DeepSeek).

---

## ðŸŽ¯ Key Features
1. **Rules Layer**  
   - Hardcoded answers for common questions (e.g., installation steps, compatibility checks, ice maker troubleshooting) to ensure 100% accurate responses.

2. **RAG Retrieval Layer**  
   - Uses OpenAI embeddings to vectorize part data and a pure Python cosine similarity search to return the top-matching part information.  
   - Strict prompt control: if retrieval results are insufficient, responds with "I'm not sure".

3. **Fallback LLM Layer**  
   - When both the Rules and RAG layers cannot answer, activates the LLM to provide general maintenance and troubleshooting suggestions.

4. **Multi-provider LLM API**  
   - Defaults to OpenAI, can switch to DeepSeek (requires setting `DEFAULT_PROVIDER` and API keys).  
   - Embeddings are always generated using OpenAI.

5. **Error Handling & Downgrade Mechanism**  
   - If DeepSeek has no credits or API key is missing, automatically falls back to OpenAI or returns a prompt message.

---

## ðŸ— System Structure & File Purpose

```plaintext
instalily-case-study-cn/
â”œâ”€â”€ backend/                     # Backend (FastAPI + RAG)
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ __init__.py          # Package initializer (can be empty)
â”‚   â”‚   â””â”€â”€ partselect_agent.py  # Main agent logic: orchestrates Rules/RAG/LLM responses
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ partselect_parts.json# PartSelect dataset (knowledge base for RAG retrieval)
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ deepseek_api.py      # DeepSeek API wrapper (error handling, timeout, etc.)
â”‚   â”‚   â”œâ”€â”€ llm_api.py           # Provider router: chooses OpenAI/DeepSeek by DEFAULT_PROVIDER
â”‚   â”‚   â””â”€â”€ openai_api.py        # OpenAI API wrapper (chat/completion unified interface)
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â””â”€â”€ rag_index.py         # RAG retrieval: vectorization, cosine similarity, Top-K retrieval
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ partselect_utils.py  # Field extraction/cleaning/formatting utilities for part data
â”‚   â”œâ”€â”€ main.py                  # FastAPI entry point: /chat API, CORS, health checks
â”‚   â””â”€â”€ requirements.txt         # Backend Python dependencies (only keep this one)
â”œâ”€â”€ frontend/                    # Frontend (React / CRA)
â”‚   â”œâ”€â”€ node_modules/            # Installed NPM packages (do not version control)
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â”œâ”€â”€ index.html           # CRA container HTML
â”‚   â”‚   â””â”€â”€ manifest.json        # PWA/resource manifest
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â””â”€â”€ api.js           # API wrapper for communicating with backend /chat
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatWindow.css   # Chat window styles
â”‚   â”‚   â”‚   â””â”€â”€ ChatWindow.js    # Chat window UI (input box, message bubbles, loading states)
â”‚   â”‚   â”œâ”€â”€ App.css              # Global styles
â”‚   â”‚   â”œâ”€â”€ App.js               # App entry point, routing/state management
â”‚   â”‚   â”œâ”€â”€ index.js             # React DOM mounting point
â”‚   â”‚   â”œâ”€â”€ reportWebVitals.js   # Performance metrics (CRA default, optional)
â”‚   â”‚   â””â”€â”€ setupTests.js        # Test initialization (CRA default, optional)
â”‚   â”œâ”€â”€ package.json             # Frontend dependencies and scripts
â”‚   â””â”€â”€ package-lock.json        # Dependency lockfile (should be version controlled)
â””â”€â”€ venv/                        # Python virtual environment (do not version control)
```

---

## âš™ï¸ Installation & Startup

### 1ï¸âƒ£ Backend
```bash
# Create and activate virtual environment
python3 -m venv venv
source venv/bin/activate

# Install backend dependencies
pip install -r backend/requirements.txt

# Set API keys
export OPENAI_API_KEY="your OpenAI API key"
export DEEPSEEK_API_KEY="your DeepSeek API key"  # optional

# Start backend server
cd backend
uvicorn main:app --reload
```
Backend runs by default on `http://127.0.0.1:8000`.

### 2ï¸âƒ£ Frontend
```bash
cd frontend
npm install
npm start
```
Frontend runs by default on `http://localhost:3000`.

---

## ðŸ’¡ Usage
The backend `/chat` API expects requests in the following format:
```json
{
  "message": "Is the water filter for model XYZ123 compatible?"
}
```
Processing steps:
1. **Rules Layer** â†’ If matched, directly return predefined answer  
2. **RAG Layer** â†’ Retrieve similar part data and generate an answer  
3. **Fallback LLM Layer** â†’ If not matched, return "I'm not sure" or give general advice  

---

## ðŸ§ª Test Cases
- **Installation Guidance**: "How to install the ice maker water inlet valve?" â†’ Matches Rules Layer  
- **Compatibility Check**: "Is part #123 compatible with model ABC456?" â†’ Matches RAG Layer  
- **Maintenance Advice**: "How often should I replace the fridge water filter?" â†’ Matches Fallback LLM Layer  
- **Out-of-scope Question**: "Which laundry detergent brand is better?" â†’ Returns "I'm not sure"  

---

## ðŸ“¦ Dependency Management (`requirements.txt`)
- **Only keep `backend/requirements.txt`**, delete root-level `requirements.txt`.  
- To freeze dependencies in the future:
```bash
source venv/bin/activate
pip freeze > backend/requirements.txt
```
or:
```bash
pip install pipreqs
pipreqs backend --force --savepath backend/requirements.txt
```

---

## ðŸš« Recommended `.gitignore`

```gitignore
# ---------- Python ----------
venv/
__pycache__/
*.py[cod]
*.pyo
*.pyd
*.so
*.log
.mypy_cache/
.pytest_cache/
.cache/
dist/
build/
.eggs/
*.egg-info/
*.sqlite
*.db


!backend/data/partselect_parts.json

.env
.env.*
*.env

# ---------- Node / React (CRA) ----------
frontend/node_modules/
frontend/.env
frontend/.env.*
frontend/build/
frontend/dist/
frontend/.parcel-cache/
frontend/.next/
npm-debug.log*
yarn-debug.log*
yarn-error.log*
pnpm-debug.log*
*.tsbuildinfo

# ---------- OS / Editors ----------
.DS_Store
Thumbs.db
.idea/
.vscode/
*.swp

# ---------- Tests / Coverage ----------
coverage/
htmlcov/
*.cover
.tox/
```

---

## ðŸ“„ License
This project is for academic and case study purposes only. Dataset source: PartSelect.
